{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bigforecast\n",
    "\n",
    "This notebook serves as the front-end for [bigforecast](https://github.com/jameslamb/bigforecast), a project completed as part of the Summer 2017 session of \"W251: Scaling Up! Really Big Data\", a course in UC-Berkeley's Master of Information in Data Science (MIDS) program.\n",
    "\n",
    "The code blocks below allow you to play with a unique dataset we've created for macroeconomic research. Like traditional datasets in econ/finance, it includes time-series of globally-important macro variables like blue chip stock prices and the price of oil. However, we also have ingested (and are still ingesting!) a corpus of global news articles from the [GDELT Event Database](https://www.gdeltproject.org/). This will allow researchers to let their curiosity take them to new and exciting places...some unorthodox features that could be used to explain financial phenomena include:\n",
    "\n",
    "* Count of articles-per-hour (globally) with the words \"financial\", \"crisis\", or \"bailout\" in the title\n",
    "* Average tone/sentiment of Wall Street Journal articles over time\n",
    "* Average tone/sentiment of non-US articles mentioning the United States Federal Reserve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dependencies\n",
    "\n",
    "Most of the code needed to interact with this system is available inside the `bigforecast` package. Anything else added below is specific to interactive work with the databases we've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bigforecast.influx as bgfi\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Modelling stuff:\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Search for Data\n",
    "\n",
    "There are two sources of data in this project: macro data stored in InfluxDB and news articles stored in Elasticsearch. In this section, we'll show how to hit these data sources to create a training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. InfluxDB\n",
    "\n",
    "InfluxDB holds time-series data from [Yahoo Finance](). Field names in this DB correspond to financial tickers on Yahoo Finance. To get a list of tickers, you can use functions available in `bigforecast`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Connect to the DB\n",
    "influxDB = bgfi.db_connect(host=\"169.53.56.26\", #os.environ['HOSTNAME']\n",
    "                           database=\"modeldb\",\n",
    "                           client_type=\"dataframe\")\n",
    "\n",
    "# List available fields:\n",
    "bgfi.list_series(db_client=influxDB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like Google and Apple's stock prices are available in there! Let's pull out a dataframe to explore these two series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a windowed dataset\n",
    "trainDF = bgfi.build_dataset(db_client=influxDB,\n",
    "                             var_list=['aapl', 'goog'],\n",
    "                             start_time='2017-08-19 18:00:00',\n",
    "                             end_time='2017-08-22',\n",
    "                             window_size='30s')\n",
    "\n",
    "# Drop NAs in the resulting DataFrame\n",
    "trainDF = trainDF.dropna(axis=0, how='any')\n",
    "\n",
    "# Print the first few rows\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train an ARIMA model\n",
    "def ARIMAmodel(RawData, lags_to_forecast):\n",
    "    RawData = RawData.values\n",
    "    size = int(len(RawData) * 0.8)\n",
    "    forecast_size = len(RawData)- size\n",
    "    #split data into training and test sets\n",
    "    train, test = RawData[0:size], RawData[size:len(RawData)]\n",
    "    train = [x for x in train]\n",
    "    test = [x[0] for x in test]\n",
    "\n",
    "    bestp, bestd, bestq = -1, -1, -1\n",
    "    best_error = 1000000\n",
    "    forecasted_values = []\n",
    "    for p in range(0,5):\n",
    "        for d in range(0,5):\n",
    "            for q in range(0,5):\n",
    "                try:\n",
    "                    model = ARIMA(train, order=(p,d,q))\n",
    "                    model_fit = model.fit(disp=0, transparams = True)  # Add transparams = True, returns statsmodels.tsa.arima.ARIMAResults class\n",
    "                    forecasted_values = [x for x in model_fit.forecast(forecast_size)[0]]\n",
    "                    error = mean_squared_error(y_true = test, y_pred = forecasted_values)\n",
    "                    if error < best_error:\n",
    "                        bestp = p\n",
    "                        bestd = d\n",
    "                        bestq = q\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    print(\"Best ARIMA model (p,d,q) : (\" + str(bestp) + \",\" + str(bestd) + \",\" + str(bestq) + \")\")\n",
    "\n",
    "    # forecast\n",
    "    if not(bestp == -1 or bestd == -1 or bestq == -1):\n",
    "        #Predict the next few lags\n",
    "        model = ARIMA(RawData, order=(bestp,bestd,bestq))\n",
    "        model_fit = model.fit(disp=0, transparams = True)\n",
    "        forecasted_values = [x for x in model_fit.forecast(lags_to_forecast)[0]]\n",
    "        return forecasted_values\n",
    "    else:\n",
    "        print(\"no valid ARIMA model\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train a VAR model\n",
    "def VARmodel(RawData, VAR, lags_to_forecast):\n",
    "    size = int(len(RawData) * 0.8)\n",
    "    forecast_size = len(RawData)- size\n",
    "\n",
    "    #split data into training and test sets\n",
    "    train, test = RawData[0:size], RawData[size:len(RawData)]\n",
    "\n",
    "    bestp = -1\n",
    "    best_error = 1000000\n",
    "    forecasted_values = []\n",
    "    for p in range(0,min(size,25)):\n",
    "        try:\n",
    "            #print(\"trying\", p)\n",
    "            train_model = VAR(train)\n",
    "            var_model = train_model.fit(p) \n",
    "            lag_order = var_model.k_ar\n",
    "            forecasted_values = [x[1] for x in var_model.forecast(train[-lag_order:].values, steps = forecast_size)]\n",
    "            error = mean_squared_error(y_true = test[\"price\"], y_pred = forecasted_values)\n",
    "            if error < best_error:\n",
    "                bestp = p\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # plot\n",
    "    if bestp != -1:\n",
    "        #Predict the next few lags\n",
    "        model = VAR(RawData)\n",
    "        var_model = train_model.fit(bestp) \n",
    "        lag_order = var_model.k_ar\n",
    "        forecasted_values = [x[1] for x in var_model.forecast(RawData[-lag_order:].values, steps = lags_to_forecast)]\n",
    "        return forecasted_values\n",
    "    else:\n",
    "        print(\"No VAR Model fitted\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "def predict(varlist = [], ticker = \"uso\", lags_to_forecast = 5, table_name=\"stockpricedemo\", start_time = \"2017-08-17\", end_time = \"2017-08-19\", interval_length = \"15m\"):\n",
    "    print(\"pulling data\")\n",
    "    list_of_data = pull_influx_data(table_name, ticker, varlist, start_time, end_time, interval_length) #add ticker\n",
    "    print(\"making dataframe\")\n",
    "    dataframe_to_model = process_list_to_dataframe(list_of_data, varlist)\n",
    "    if varlist == []:\n",
    "        #use arima model\n",
    "        print(\"Running ARIMA model\")\n",
    "        predicted_values = ARIMAmodel(dataframe_to_model, lags_to_forecast)\n",
    "        print \"----------------------\"\n",
    "        print \"ARIMA model predicts the next\", lags_to_forecast, \"lags to be:\" , predicted_values\n",
    "        print \"----------------------\"\n",
    "    else:\n",
    "        #use VAR model\n",
    "        hello=1\n",
    "        print(\"Running VAR model\")\n",
    "        predicted_values = VARmodel(dataframe_to_model, VAR, lags_to_forecast)\n",
    "        print \"----------------------\" \n",
    "        print \"VAR model predicts the next\", lags_to_forecast, \"lags to be:\" ,  predicted_values\n",
    "        print \"----------------------\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Produce Forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (bigforecast)",
   "language": "python",
   "name": "bigforecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
